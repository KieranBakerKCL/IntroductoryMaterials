{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84ebd5f1",
   "metadata": {},
   "source": [
    "# Scale Up With Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a265f9",
   "metadata": {},
   "source": [
    "## Part 1: Let's Get Coding\n",
    "\n",
    "**Contents:**\n",
    "\n",
    "* **This is a Jupyter Notebook**\n",
    "* **Basic Python data types**\n",
    "    * Strings\n",
    "    * Integers/Float\n",
    "    * Boolean\n",
    "    * Sequences (Lists)\n",
    "    * Mappings (Dictionaries)\n",
    "    \n",
    "    \n",
    "* **What can we do with this data?**\n",
    "    * Variables\n",
    "    * Methods\n",
    "    * Loops\n",
    "    * Conditional Logic\n",
    "    * Functions\n",
    "    \n",
    "    \n",
    "* **Other data objects?**\n",
    "    * Install/Import\n",
    "    * A few more types\n",
    "    * Pandas DataFrames walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c1f5dc",
   "metadata": {},
   "source": [
    "### Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ec7766",
   "metadata": {},
   "source": [
    "Kernel: underlying environment/files for a given session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ba69b1",
   "metadata": {},
   "source": [
    "Here is an empty cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1ce688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85e2a06a",
   "metadata": {},
   "source": [
    "Here is a cell with a comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528783aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic comment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67cf2a1",
   "metadata": {},
   "source": [
    "Please create another cell:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0491ec2",
   "metadata": {},
   "source": [
    "### Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf89267",
   "metadata": {},
   "source": [
    "###### Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c160ab9",
   "metadata": {},
   "source": [
    "[Strings](https://docs.python.org/3/library/stdtypes.html#text-sequence-type-str) - *a proxy for raw text, signified by quote enclosure*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3a77a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'Howdy!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0ea79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can be empty\n",
    "''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b917069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Triple quotation allows for linebreaks\n",
    "\"\"\"Well here's a lengthy piece of\n",
    "\n",
    "\n",
    "\n",
    "text\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93243cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Even non-'text' items are strings if enclosed by quotation marks\n",
    "'20'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b8d920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check data type\n",
    "type('20')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6644e6",
   "metadata": {},
   "source": [
    "[Integers](https://docs.python.org/3/library/stdtypes.html#numeric-types-int-float-complex) - *whole numbers*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc7401b",
   "metadata": {},
   "outputs": [],
   "source": [
    "100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eebd46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can perform operations on integers\n",
    "100+20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d664c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can perform operations on integers\n",
    "100*20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b5743e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check data type\n",
    "type(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdf32f3",
   "metadata": {},
   "source": [
    "[Float](https://docs.python.org/3/library/stdtypes.html#numeric-types-int-float-complex) - *all real numbers, signified with decimal point*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409cc62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9920b115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can perform operations on floats\n",
    "100.0+20.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f53330f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can perform operations on floats and integers -> mixed arithmetic \n",
    "100.0**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d7e735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check data type\n",
    "type(20.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72df0ee6",
   "metadata": {},
   "source": [
    "Boolean - *logical type, either yes or no (True or False), no quotation marks!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2d7e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5db5cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90454d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can go between integer/boolean\n",
    "bool(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da9d472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can go between integer/boolean\n",
    "bool(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded51b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean does not equal string!\n",
    "True=='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f337ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can't easily convert from string!\n",
    "bool('False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6462149c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check data type\n",
    "type(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd9b2b1",
   "metadata": {},
   "source": [
    "[None](https://docs.python.org/3/reference/datamodel.html#none) - *Nada, Zilch, Nothing at All*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec42b34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f67563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check data type\n",
    "type(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafd8367",
   "metadata": {},
   "source": [
    "###### [Sequences ](https://docs.python.org/3/reference/datamodel.html#sequences)\n",
    "* Excluding Tuples/Ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99067361",
   "metadata": {},
   "source": [
    "Lists - *flexible, mutable, ordered group of data objects*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9bf336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can consist of multiple data types\n",
    "[1,3,'10',None,15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16cc33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List can contain list\n",
    "[1,3,[10,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a0947f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can be combined\n",
    "[1,3,'10',None,15]+['17']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a680d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordered: can subselect items - FROM ZERO\n",
    "[1,3,'10',None,15][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1b0d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index 3 is actually the fourth entry in the sequence\n",
    "[1,3,'10',None,15][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfd6de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative indicies select in reverse\n",
    "[1,3,'10',None,15][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672dd5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index 10 doesnt exist\n",
    "[1,3,'10',None,15][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7241d68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can select a range of entries, does not include endpoint\n",
    "[1,3,'10',None,15][0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d30b767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check data type\n",
    "type([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3f92b7",
   "metadata": {},
   "source": [
    "###### [Mapping ](https://docs.python.org/3/reference/datamodel.html#mappings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0d8d99",
   "metadata": {},
   "source": [
    "Dictionaries - *set of mappings based on key,value pairs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c6ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value type flexible\n",
    "{'integer':10,\n",
    "'float':8.5,\n",
    "'string':'numbers'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c714dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can't have multiple instances of the same word in a dictionary -> must be single key but can have multiple definitions (list)\n",
    "{'entry1':5,\n",
    "'entry2':[10,20],\n",
    "'entry1':(5.0,5.0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8221fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can 'lookup' dictionary value\n",
    "{'integer':10,\n",
    "'float':8.5,\n",
    "'string':'numbers'}['integer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4080e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check data type\n",
    "type({'integer':10,\n",
    "'float':8.5,\n",
    "'string':'numbers'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d14951",
   "metadata": {},
   "source": [
    "### [Variables](https://realpython.com/python-variables/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fda5e2b",
   "metadata": {},
   "source": [
    "Some basic examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c24e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set\n",
    "fruit='apple'\n",
    "print(fruit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d1fc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare\n",
    "building_1=105.5\n",
    "building_2=200.6\n",
    "\n",
    "building_2-building_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6523c30b",
   "metadata": {},
   "source": [
    "Dictionary Operations - *too verbose to define and subselect all in one cell, let's use a variable to simplify*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfad56a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set\n",
    "shopping_list={'apple':6,\n",
    "'banana':4,\n",
    "'hobnob (pack)':1,\n",
    "'salmon':2,\n",
    "'crab':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4322628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lookup\n",
    "shopping_list['apple']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501c7569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating\n",
    "shopping_list['salmon']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae77ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View\n",
    "shopping_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b9aa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method - view keys\n",
    "shopping_list.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572293c9",
   "metadata": {},
   "source": [
    "List Operations - *too verbose to define and subselect all in one cell, let's use a variable to simplify*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc499eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set/View\n",
    "inventory=['apple','banana','pear','jackfruit','digestives (pack)','penguins (pack)',\n",
    "           'hobnob (pack)','rice (pack)','potato','cod','prawns','seabass','salmon','tuna']\n",
    "\n",
    "inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d79176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subselect\n",
    "inventory[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d6aa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method - add item\n",
    "inventory.append('snickers')\n",
    "inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915983f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method - add many items (list)\n",
    "inventory.extend(['galaxy'])\n",
    "inventory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98822e4d",
   "metadata": {},
   "source": [
    "Assignment vs Logic - *how do we compare variables?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2e7ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single '=' signifies assignment\n",
    "inventory[-1]='haddock'\n",
    "inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdcebb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double '==' signifies comparison -> returns boolean\n",
    "inventory[-1]=='haddock'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029a180c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double '!=' signifies comparison -> returns boolean\n",
    "inventory[-1]!='tuna'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b867c888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can use 'in' to check if value exists in sequence -> returns boolean\n",
    "'haddock' in inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3354443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can use 'in' to check if value exists in sequence -> returns boolean\n",
    "'Haddock' in inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce04800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can use 'and' (&) to combine multiple pieces of logic -> returns boolean\n",
    "('haddock' in inventory) & ('wine' in inventory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7a316b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can use 'or' (|) to combine multiple pieces of logic -> returns boolean\n",
    "('haddock' in inventory) | ('wine' in inventory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776e1c98",
   "metadata": {},
   "source": [
    "### What can we do with these variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d57dd02",
   "metadata": {},
   "source": [
    "[Conditional Statements](https://docs.python.org/3/tutorial/controlflow.html) - *performs action depending on logic*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7199407",
   "metadata": {},
   "outputs": [],
   "source": [
    "item='apple'\n",
    "\n",
    "if item in inventory:\n",
    "    print('In Inventory')\n",
    "else:\n",
    "    print('Unavailable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87184877",
   "metadata": {},
   "outputs": [],
   "source": [
    "item='grapefruit'\n",
    "\n",
    "if item in inventory:\n",
    "    print('In Inventory')\n",
    "else:\n",
    "    print('Unavailable')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91403576",
   "metadata": {},
   "source": [
    "[Loops](https://docs.python.org/3/tutorial/datastructures.html#looping-techniques) - *iterate through sequence*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37530c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loop\n",
    "for item in inventory:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca3ffec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# While loop - be careful of infinite loop\n",
    "i=0\n",
    "\n",
    "while i<12:\n",
    "    print(inventory[i])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3defb2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can combine loops and conditional statements\n",
    "all_items_shopping_list={}\n",
    "\n",
    "# Loop through each item in stores inventory\n",
    "for item in inventory:\n",
    "\n",
    "    # Check if item is in shopping list\n",
    "    if item in shopping_list.keys():\n",
    "        # If item in shopping list, add to all_items_shopping_list with desired purchase volume\n",
    "        all_items_shopping_list[item]=shopping_list[item] \n",
    "        \n",
    "    else:\n",
    "        # If item in not shopping list, add to all_items_shopping_list with purchase volume equals zero\n",
    "        all_items_shopping_list[item]=0      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3eea1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_items_shopping_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c515304",
   "metadata": {},
   "source": [
    "###### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e388131d",
   "metadata": {},
   "source": [
    "Native"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a64044f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Universal: View object below cell\n",
    "print(all_items_shopping_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae461032",
   "metadata": {},
   "source": [
    "[Custom](https://docs.python.org/3/tutorial/controlflow.html#defining-functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4cff14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create price dictionary\n",
    "inventory_price_dict={\n",
    "'apple':0.25,\n",
    "'banana':0.25,\n",
    "'pear':0.3,\n",
    "'jackfruit':0.6,\n",
    "'digestives (pack)':1.5,\n",
    "'penguins (pack)':2,\n",
    "'hobnob (pack)':2,\n",
    "'rice (pack)':2.5,\n",
    "'potato':0.5,\n",
    "'cod':3.5,\n",
    "'prawns':4,\n",
    "'seabass':5,\n",
    "'salmon':4,\n",
    "'tuna':5,\n",
    "'snickers':0.75,\n",
    "'haddock':3    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0777fe60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to calculate total price of shop based on input dictionary 'shopping_list'\n",
    "\n",
    "def shopping_spend(shopping_list:dict,inventory_price_dict:dict):\n",
    "    \n",
    "    # Spend starts at zero\n",
    "    spend=0\n",
    "\n",
    "    # Loop through each item in your shopping list\n",
    "    for item in shopping_list.keys():\n",
    "        \n",
    "        # Check if item in available in inventory\n",
    "        if item in inventory_price_dict.keys():\n",
    "            # If item available, multiply cost by purchase volume and add to existing spend total\n",
    "            spend+=inventory_price_dict[item]*shopping_list[item]\n",
    "        \n",
    "        # Check if item unavailable, add zero to spend and move onto the next item on the shopping list    \n",
    "        else:\n",
    "            spend+=0\n",
    "    \n",
    "     # After looping through complete shopping list, return total spend\n",
    "    return(spend)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f584e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run shopping_spend function over shopping list\n",
    "shopping_spend(shopping_list,inventory_price_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a941237",
   "metadata": {},
   "source": [
    "### [Packages](https://docs.python.org/3/tutorial/modules.html#packages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423bcf67",
   "metadata": {},
   "source": [
    "pip install - *standard method of installing python packages/libraries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b9c243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '!' sends command to Terminal\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d658a331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# includes installation of dependencies \n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05d02f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# includes installation of dependencies \n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4d8ea7",
   "metadata": {},
   "source": [
    "Let's Import A Couple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4057fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import whole package as variable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266b1dc9",
   "metadata": {},
   "source": [
    "### [Pandas DataFrames](https://pandas.pydata.org/docs/user_guide/dsintro.html)\n",
    "\n",
    "* Pandas is a common package used for data analytics\n",
    "* It is dependant on NumPy and several other libraries\n",
    "* The main benefit is it's easy to use 'DataFrame' object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2025436b",
   "metadata": {},
   "source": [
    "Introduction - *what does an unseen dataframe look like?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b376c178",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import ready-made pandas dataframe\n",
    "sample_df = sns.load_dataset('iris')\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90eb8209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at every row\n",
    "pd.set_option('display.max_rows', 150)\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cf485b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's just look at the first few\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13049519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the column types\n",
    "sample_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5289456e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the (numeric) column values\n",
    "sample_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcedd426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any None values?\n",
    "sample_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8674fe8",
   "metadata": {},
   "source": [
    "Under The Hood - *you've already seen DataFrames (sort of)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978daec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A DataFrame is just a dictionary of dictionaries!\n",
    "sample_df.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5820a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at this again\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5232c572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column selection is the same as dictionary value lookup\n",
    "sample_df['sepal_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252ab0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of an outright dictionary this is a special Pandas data type called a 'Series'\n",
    "type(sample_df['sepal_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b607b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's lookup the first value of this 'Series'\n",
    "sample_df['sepal_length'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f87d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's native type we recognise! Float\n",
    "type(sample_df['sepal_length'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21aa4efc",
   "metadata": {},
   "source": [
    "Let's Create Our Own From Scratch!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d72fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting with the price dictionary\n",
    "inventory_price_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162cf71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can reformat into a DataFrame (don't need to understand syntax unless you're interested)\n",
    "food_price_df=pd.DataFrame.from_dict(inventory_price_dict,orient='index',columns=['Price']).reset_index().rename(columns={'index':'Item'})\n",
    "food_price_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450c922f",
   "metadata": {},
   "source": [
    "Let's Import Data as a DataFrame!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d646cc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import csv using inbuilt pandas (pd) function [read_csv]\n",
    "food_guide_df=pd.read_csv('Food_Guide.csv')\n",
    "food_guide_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97640d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at types...no list specificity\n",
    "food_guide_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6be05a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's convert Allergens to list via one-line loop and 'ast' package\n",
    "import ast\n",
    "\n",
    "food_guide_df['Allergens']=[ast.literal_eval(x) for x in food_guide_df['Allergens'].fillna(\"[]\")]\n",
    "food_guide_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26a4c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(food_guide_df['Allergens'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a3caaf",
   "metadata": {},
   "source": [
    "Data Wrangling Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473ba456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subselect Row For Stacking\n",
    "food_guide_df[15:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784787d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack data using inbuilt pandas (pd) function [concat]\n",
    "food_guide_df_duped=pd.concat([food_guide_df,food_guide_df[15:]]).reset_index(drop=True)\n",
    "food_guide_df_duped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8144a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dedupe data using inbuilt pandas (pd) DataFrame method [drop_duplicates]\n",
    "food_guide_df_deduped=food_guide_df_duped.drop_duplicates(subset='Item')\n",
    "food_guide_df_deduped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3116858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge data using inbuilt pandas (pd) DataFrame method [merge]\n",
    "food_guide_price_df=food_guide_df_deduped.merge(food_price_df)\n",
    "food_guide_price_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6c912d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode list column using inbuilt pandas (pd) DataFrame method [explode]\n",
    "food_guide_price_df_long=food_guide_price_df.explode('Allergens').fillna('').reset_index(drop=True)\n",
    "food_guide_price_df_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae456fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat dataframe using inbuilt pandas (pd) DataFrame methods [groupby/apply]\n",
    "food_guide_price_df_wide=food_guide_price_df_long.groupby(['Item','Health_Rating','Price'])['Allergens'].apply(list).reset_index()\n",
    "food_guide_price_df_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eec61ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to dataframe\n",
    "food_guide_price_df_long['Price_Inflated']=food_guide_price_df_long['Price']*1.05\n",
    "food_guide_price_df_long"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd36fd1",
   "metadata": {},
   "source": [
    "[Basic Data Analysis](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82971fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subselect Rows\n",
    "food_guide_price_df_long[10:15]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1d50a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subselect Columns\n",
    "food_guide_price_df_long[['Item','Health_Rating']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67563de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subselect both Rows and Columns using inbuilt pandas DataFrame method (loc)\n",
    "food_guide_price_df_long.loc[10:15,['Item','Health_Rating']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0c0330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can filter rows using boolean comparison\n",
    "food_guide_price_df_long['Price']>2.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d136bb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can filter rows using boolean comparison\n",
    "spenny_food=food_guide_price_df_long[food_guide_price_df_long['Price']>2.0]\n",
    "spenny_food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cae4411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's sort resultant DataFrame\n",
    "spenny_food.sort_values('Price',ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc76bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use inbuilt pandas (pd) DataFrame method [value_counts]\n",
    "spenny_food.sort_values('Health_Rating')['Health_Rating'].value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e943c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use inbuilt pandas (pd) DataFrame methods [groupby/mean] to query dataframe\n",
    "spenny_food.sort_values('Health_Rating').groupby('Health_Rating')['Price'].mean().reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b674ad",
   "metadata": {},
   "source": [
    "## Part 2: Okay, Let's *Really* Get Programming\n",
    "\n",
    "#### Contents:\n",
    "\n",
    "* **Querying of Dataframes**\n",
    "    * AND statements\n",
    "    * OR statements\n",
    "    * Crazy statements\n",
    "    \n",
    "* **Plotting with Pandas and Matplotlib**\n",
    "    * Histograms and KDEs\n",
    "    * Box plots\n",
    "    * Grouped box plots\n",
    "    * Heat maps\n",
    "* **Handling missing data**\n",
    "    * Finding missing data in dataframes\n",
    "    * Simple imputation\n",
    "    * Multiple imputation\n",
    "* **Building some simple machine learning models** (Linear Regression and Random Forests)\n",
    "    * `food_guide_price_df`\n",
    "    * `sample_df`\n",
    "    * `diabetes_df`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d252e86e",
   "metadata": {},
   "source": [
    "## Querying of Dataframes\n",
    "We have seen how to do some fairly simple filtering of dataframes based on certain values, let's look at some more complex filtering based on multiple criteria, and using AND and OR statements.\n",
    "\n",
    "First off we will see that we can also filter dataframes using the ```.loc[]``` method. As in the example we have seen previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404a8711",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_guide_price_df.loc[food_guide_price_df['Price']>2.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5eeb4a",
   "metadata": {},
   "source": [
    "and we can see that our jupyter output is the same as before. If we want to fulter on multiple statements, we can use the ```&``` operator. Suppose we want to get all groceries costing more that £2 with a health rating of B:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e921b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_guide_price_df.loc[(food_guide_price_df['Price']>2.0) & (food_guide_price_df['Health_Rating']=='B')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842b6e72",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Important:</b> Note in the code snippet above that there are brackets around each filter, this is necessary!\n",
    "</div>\n",
    "\n",
    "When applying multiple filters, the code should appear like\n",
    "\n",
    "```df.loc[(filter_1) & (filter_2) & (filter_3) & ...]```\n",
    "\n",
    "We can look for records in our dataframe where the price is less than £2 and the health rating is a B:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0460aa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_guide_price_df.loc[(food_guide_price_df['Price']<2.0) & (food_guide_price_df['Health_Rating']=='B')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079115b7",
   "metadata": {},
   "source": [
    "The empty dataframe response tells us that there are indeed no records satisfying both of those filter conditions.\n",
    "\n",
    "In the cell below, write some code to filter the ```food_guide_price_df``` where the price is more than £2.50 and the health rating is A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273131ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4880c02b",
   "metadata": {},
   "source": [
    "If the record for salmon was the only record to come back, that's the correct result! If not, have another look at the examples and see if there's an issue somewhere.\n",
    "\n",
    "Now let's have a look at or statements, indicated by the ```|``` operator - yes, you finally get to use this key on your keyboard! Suppose we want to see all food items with a health rating of an A or a C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc94d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_guide_price_df.loc[(food_guide_price_df['Health_Rating']=='A') | (food_guide_price_df['Health_Rating']=='C')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c8f0c8",
   "metadata": {},
   "source": [
    "Now it is a little annoying that we can't see the whole piece of code on one line... we can insert new lines in the middle of these statements without it causing an issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7e136d",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_guide_price_df.loc[(food_guide_price_df['Health_Rating']=='A') | \n",
    "                             (food_guide_price_df['Health_Rating']=='C')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23b721e",
   "metadata": {},
   "source": [
    "Now try yourself listing out both the cheap and expensive items: that is, those with a price lower than £0.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84235a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_guide_price_df.loc[(food_guide_price_df['Price']<0.5) | (food_guide_price_df['Price']>4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83618dfe",
   "metadata": {},
   "source": [
    "If you are getting back the data for apples, bananas, pears, seabass and tuna, that's correct! Anything else and you'll need to check your code and tweak it a little.\n",
    "\n",
    "Finally, the holy grail where the flexibility of Python extends the filtering you can do in Excel: combinations of AND and OR statements! We can really combine these things in as many ways as we like. Say I want to see either foods with a health rating of A and less than £1, or a health rating of E and a price of more than £1, we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c73513",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_guide_price_df.loc[\n",
    "    (\n",
    "        (food_guide_price_df['Price']<1) & (food_guide_price_df['Health_Rating']=='A')\n",
    "    ) \n",
    "    | \n",
    "    (\n",
    "        (food_guide_price_df['Price']>1) & (food_guide_price_df['Price']=='E')\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9bf586",
   "metadata": {},
   "source": [
    "Now you may think we have formatted the code very strangely in the code cell above, but that's because we wanted to emphasise the format of the brackets. Remember that **each condition needs to have brackets around it** when running multiple filters. This is true when we are nesting logic in this way. Simplifying the code above, what we have written follows the following structure\n",
    "                    \n",
    "```df.loc[( (filter1)&(filter2) ) | ( (filter3)&(filter4) )]```\n",
    "\n",
    "See how that the conditions either side of the OR clause are also bracketed. Now do some practice and try constructing all different types of filters, we can combine AND and OR statments is *any way*, so think of some different combinations you might want to try out yourself. A couple of ideas if you need some inspiration are:\n",
    "\n",
    "```df.loc[( (filter1)&(filter2) ) | (filter3) | (filter4)]```\n",
    "\n",
    "```df.loc[( (filter1)|(filter2) ) & (filter3) ]```\n",
    "\n",
    "If you wanted to practice on a dataset with some more variables, you can always use ```sample_df``` instead of ```food_guide_price_df```. We have left a few blank cells below for you use use, but feel free to add in some more if you need them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b4d3fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b196421",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1a0556",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8433a8ba",
   "metadata": {},
   "source": [
    "I am sure you can see how this flexibility of querying data, alongside the functionality like `explode`, `merge`, `pivot` that you have seen earlier, is incredibly powerful in allowing users to understand the data they are looking at from different sources. Take a look at the next section to see how plots can also help you with your exploratory data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457b7d4c",
   "metadata": {},
   "source": [
    "## Plotting with Pandas and Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6972c2a",
   "metadata": {},
   "source": [
    "We can do some simple plots with `pandas` which make life really easy. The code follows the following structure\n",
    "\n",
    "```df['col'].plot.plot_type()```\n",
    "\n",
    "where you will swap out ```plot_type()``` for the plot that you want. For example, we can easily plot continuous data like prices in a histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42e978c",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_guide_price_df['Price'].plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1725324",
   "metadata": {},
   "source": [
    "There is a type of plot called a __[Kernel Density Estimate](https://en.wikipedia.org/wiki/Kernel_density_estimation)__ (KDE) which does a similar job to a histogram but avoids categorising the data - the tails that run below 0 and above 5 are a feature of the KDEs, and they are far more useful with larger amounts of data. Also note that the y-axis has a different scale, this is because KDEs actually return __[probability densities](https://en.wikipedia.org/wiki/Probability_density_function)__, but this is not something to worry about for now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfe86c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_guide_price_df['Price'].plot.kde()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1d32d7",
   "metadata": {},
   "source": [
    "We can also plot counts of categorical variables using the pandas ```value_counts()``` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40f9ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_guide_price_df['Health_Rating'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c18c3d1",
   "metadata": {},
   "source": [
    "Now we can see that the order of the axis is a little annoying, we really would like them to appear in logical order, which we can control by ordering the series with ```sort_values()``` before we plot, and adding the ```sort=False``` argument to the ```value_counts``` method, as in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9f2cac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "food_guide_price_df['Health_Rating'].sort_values().value_counts(sort=False).plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47246258",
   "metadata": {},
   "source": [
    "Now try constructing a couple of plots for the ```sample_df```:\n",
    "* A histogram of the ```petal_length``` column\n",
    "* A bar chart showing counts for the ```species``` column\n",
    "* A KDE for the ```sepal_length``` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67678de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2569f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142de609",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3169aba7",
   "metadata": {},
   "source": [
    "Here is a list of all the different plots offered to us in Pandas:\n",
    "* ‘line’ : line plot (default)\n",
    "* ‘bar’ : vertical bar plot\n",
    "* ‘barh’ : horizontal bar plot\n",
    "* ‘hist’ : histogram \n",
    "* ‘box’ : boxplot\n",
    "* ‘kde’ : Kernel Density Estimation plot\n",
    "* ‘density’ : same as ‘kde’\n",
    "* ‘area’ : area plot\n",
    "* ‘pie’ : pie plot\n",
    "* ‘scatter’ : scatter plot (DataFrame only)\n",
    "* ‘hexbin’ : hexbin plot (DataFrame only)\n",
    "\n",
    "Have a look at the __[Pandas .plot documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html)__ to see some other arguments that can be added to plotting methods to customise your plots, and you can see more examples of this in the __[Pandas visualisation guide](https://pandas.pydata.org/docs/user_guide/visualization.html)__.\n",
    "\n",
    "The Pandas plotting functionality is all bought to us via `matplotlib` - and those who already have some Python experience might find this __[interactive Binder notebook](https://mybinder.org/v2/gh/matplotlib/mpl-brochure-binder/main?labpath=MatplotlibExample.ipynb)__ an interesting example of some of the more complex visualisation tools that `matplotlib` provide. But let's look at some more interesting plots of our data using `matplotlib`. First we import the `pyplot` module from `matplotlib` under the alias `plt` that actually manages all the plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f2959e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df280ac",
   "metadata": {},
   "source": [
    "Have you heard of a box-plot before? It tells us about the shape of our data by presenting the minimum and maximum points, along with the quartiles - that is the 25%, 50% and 75% positions of the data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891d89f6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.boxplot(food_guide_price_df['Price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca09305f",
   "metadata": {},
   "source": [
    "Now this is not the neatest boxplot. We can tidy this up in a few ways: we will\n",
    "* Remove the label on the x-axis\n",
    "* Add a label to the y-axis\n",
    "* Add a title to our plot\n",
    "* Remove the redundant cell output above the image\n",
    "\n",
    "We will do this by defining a space for the plot which we have full control over, called a ```subplot```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f590fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the subplot we will plot against\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Add to boxplot to the figure. We use labels = [''] to replace the x-label with an empty string\n",
    "ax.boxplot(food_guide_price_df[['Price']], labels = [''])\n",
    "\n",
    "# We can use set_xlabel(), set_ylabel() and set_title() to add these to our plots\n",
    "ax.set_ylabel('Price (£)')\n",
    "ax.set_title('Box plot of grocery price'); \n",
    "# The use of the semicolon at the end of the cell removes the redundant output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e84f520",
   "metadata": {},
   "source": [
    "Boxplots are commonly presented horizontal which makes them a little easier to read, and they take up less space on the page. We do this by setting the ```vert``` argument of the boxplot function to ```False```. Note that in swapping the orientation, we are now using ```set_xlabel``` instead of ```set_ylabel```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f03a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(food_guide_price_df[['Price']], labels = [''], vert=False)\n",
    "ax.set_xlabel('Price (£)')\n",
    "ax.set_title('Box plot of grocery price'); "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7184bb96",
   "metadata": {},
   "source": [
    "We can actually break this price information down by grouping it by the health rating. We can do this by creating a dictionary which you have seen earlier. The keys of our dictionary will be the different health ratings, and the values will be lists of the values for that health category. It is important when programming to be able to move between different types of objects so have all options at your disposal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f6bbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grocery_dict = {}\n",
    "\n",
    "# We sort the values to get them in the order we want to present them in\n",
    "health_ratings = food_guide_price_df['Health_Rating'].sort_values().unique()\n",
    "\n",
    "# We will iterate through each health rating and add the results to the dictionary as we go\n",
    "for rat in health_ratings:\n",
    "    # Obtain the prices for each health rating\n",
    "    prices = food_guide_price_df.loc[food_guide_price_df['Health_Rating'] == rat]['Price']\n",
    "    \n",
    "    # We need this as a list, so we use the .to_list() method\n",
    "    prices_list = prices.to_list()\n",
    "    \n",
    "    # Add the results to the dictionary\n",
    "    grocery_dict[rat] = prices_list\n",
    "    \n",
    "grocery_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89cbd46",
   "metadata": {},
   "source": [
    "Now we create the boxplot by inputting the values of the dictionary, and setting the x-axis as the keys of the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6c819a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, ax = plt.subplots()\n",
    "ax.boxplot(grocery_dict.values(), labels=grocery_dict.keys(), vert=False)\n",
    "ax.set_xlabel('Price')\n",
    "ax.set_ylabel('Health Rating')\n",
    "ax.set_title('Grocery Price by Health Rating');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddeca793",
   "metadata": {},
   "source": [
    "The boxes look a little funny because there are very small amounts of data, and in some cases, not enough to get different values for the quartiles, but we can still see some interesting things. The price varies considerably by price - foods with a health rating of A are cheaper than all other health ratings, and foods with a health rating of B are considerably higher in price than all other health ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac2b924",
   "metadata": {},
   "source": [
    "Give this a try yourself now! Using the `sample_df`, create box plots for `petal width` and `petal length`. Then create box plots for these variables grouped by the species type, and see if any interesting patterns appear. You will need to write the code to create the analagous dictionaries in the example above, and then use the dictionaries to plot the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512578c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132cdd90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a8a75a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2603d62b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e45e31f",
   "metadata": {},
   "source": [
    "We can also construct interesting scatter graphs with `matplotlib`. I will demonstrate this using `sample_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1135486",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.scatter(x = sample_df['sepal_width'], y = sample_df['petal_width'])\n",
    "ax.set_xlabel('Sepal Width')\n",
    "ax.set_ylabel('Sepal Length');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7dae45",
   "metadata": {},
   "source": [
    "It almost looks like it breaks into two different clusters...perhaps this is due to the different species we have collected data from! Let's colour the points by species to see if this reveals anything interesting. *Note the american spelling of the argument* `color`*, it gets me every time!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dbd7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.scatter(x = sample_df['sepal_width'], y = sample_df['petal_width'], color = sample_df['species'])\n",
    "ax.set_xlabel('Sepal Width')\n",
    "ax.set_ylabel('Sepal Length');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e15f1f6",
   "metadata": {},
   "source": [
    "Ah, an error! This is because life isn't always as easy as we might like it to be. We cannot simply just insert the column into the `color` argument. Instead, we will have to plot the points for each species in stages, which will give us the different colours. And yes, error messages and traceback in Python can sometimes be very long and complicated to understand, often only the last line is the bit you really need which will point you to the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52065f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "species = sample_df['species'].unique()\n",
    "for s in species:\n",
    "    species_df = sample_df.loc[sample_df['species'] == s]\n",
    "    ax.scatter(x = species_df['sepal_width'], y = species_df['petal_width'])\n",
    "ax.set_xlabel('Sepal Width')\n",
    "ax.set_ylabel('Sepal Length');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c380c1",
   "metadata": {},
   "source": [
    "So there is some underlying pattern based on the species! Though, we do not know which species comes to which colour. We can sort this out by applying a `label` to each scatter plot, and then adding a `legend`, also known as a key, to our plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f19c4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "species = sample_df['species'].unique()\n",
    "for s in species:\n",
    "    species_df = sample_df.loc[sample_df['species'] == s]\n",
    "    ax.scatter(x = species_df['sepal_width'], y = species_df['petal_width'], label = s)\n",
    "ax.set_xlabel('Sepal Width')\n",
    "ax.set_ylabel('Sepal Length')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e53424",
   "metadata": {},
   "source": [
    "This plot tells us that we could probably build a pretty good classification model for species based on both the sepal width and sepal length. Using all of the things you have learned about plotting so far, see what other interesting combinations of variables you can plot - do other combinations of variables appear to discriminate between species of iris flower?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b751678e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f78ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9ddc91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "197132cf",
   "metadata": {},
   "source": [
    "Now we will quickly look at one other type of plot - a heatmap. This can be very useful when exploring relationships beteween variables, like *correlation*. Correlation is a measure between -1 and 1 that describes the relationship between two variables. A correlation of 1 means that as one increases, the other certainly increases, and a correlation of -1 means that as one increases, the other certainly decreases. Note that it **does not** measure how much the increase or decrease is. We can very easily obtain correlations between variables in pandas! Let's remove the `species` column from `sample_df` and then calculate the correlation between the other variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6fe46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_df = sample_df.drop('species', axis=1).corr()\n",
    "cor_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92fdc1a",
   "metadata": {},
   "source": [
    "We can plot this very nicely on a heat map! Now, `matplotlib` does not have any easy implementation of heat map plots, so we turn to another plotting library called `seaborn`. We import it under the alias `sns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1813d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(cor_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0ff284",
   "metadata": {},
   "source": [
    "One thing we may want to implement to improve this plot is to have the scale start at -1 instead of -0.4. We might also want stronger colours at -1 and 1, with a very light colour at 0. We can make these changes! Firstly by adding the arguments `vmin` and `vmax` to the `heatmap` function, we can change the colour scale. Seaborn has a whole load of built in __[colour maps](https://seaborn.pydata.org/tutorial/color_palettes.html)__ which we can take advantage of here, we will use the `vlag` colour palette."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5144d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cor_df, vmin = -1, vmax = 1, cmap = 'vlag')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1833a6",
   "metadata": {},
   "source": [
    "We can now very easily see the very strong correlation structure in the iris dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da211fab",
   "metadata": {},
   "source": [
    "## Handling missing data\n",
    "Missing data appears almost everywhere! It's not something we have to deal with at Acin very often - unless we think of prospect data as missing... ;) - but in other applications, for example medical data, it's an inevitability. In this section we will have a look at how we identify missing data, some simple methods for dealing with the issue, and touch on some more golden-standard methods.\n",
    "\n",
    "I will be demonstrating methods with the `food_guide_price_df` dataset having deleted a set of values, but you will be practicing with the `diabetes_df` dataset taken from __[Kaggle](https://www.kaggle.com/datasets/akshaydattatraykhare/diabetes-dataset)__. This is a real dataset which I have ommitted some values from. Below you can see the first 5 rows of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed1cddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df = pd.read_csv('diabetes.csv')\n",
    "diabetes_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450286a9",
   "metadata": {},
   "source": [
    "### Finding missing data in dataframes\n",
    "Firstly we will add in some missing values to our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95f91b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_indices = [2,5,10,14,12,14]\n",
    "food_missing = food_guide_price_df.copy()\n",
    "\n",
    "# we replace the price value at these indices to the missing type None\n",
    "food_missing.loc[missing_indices, 'Price'] = None\n",
    "\n",
    "food_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dfc47e",
   "metadata": {},
   "source": [
    "There are useful methods to help us locate missing data in a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cf1458",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_missing.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77135013",
   "metadata": {},
   "source": [
    "We can see that the values that are missing are identified as True in the table above. For large datasets, it can be useful to see a heatmap to identify where values are missing. In the section on plotting, we cover generating heatmaps with `seaborn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0186b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(food_missing.isna())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d9de06",
   "metadata": {},
   "source": [
    "We can see that when we do heatmaps of boolean variables, 0 corresponds to `False` (in our case, a value that is not missing), and 1 corresponds to True (a missing value). For small datasets, this is perhaps a little excessive, but try this out with the diabetes dataset, `diabetes_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0667f0d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c869d0f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Advanced Exercise:</b> For those who are a little more confident working with Python, take a look at <a href=\"https://towardsdatascience.com/using-the-missingno-python-library-to-identify-and-visualise-missing-data-prior-to-machine-learning-34c8c5b5f009\">this example</a> which uses the <i>missingno</i> package to construct some more advanced summaries of the missing data.\n",
    "</div>\n",
    "\n",
    "The process by which we aim do deal with this missing data is called *imputation*. It is possible to do a complete case analysis (CCA), but this involves throwing away important data that we might want to use. Moreover statistically it is not always right to just not use this data as there maybe some mechanism causing missing data [ i.e. the data is 'missing not at random' (MNAR) instead of 'missing completely at random' (MCAR) ] - an example of this would be that, perhaps in a study, people who are older are more reluctant to provide their age. Getting rid of this data means that any results are biased/not relevent to the older population. The field of missing data management in statistics is vast with new methods aimed to minimise biases caused by missing data, and managing different types of missing data all the time!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6481037d",
   "metadata": {},
   "source": [
    "We can filter dataframes using the `isna()` or `notna()` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29feba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_missing.loc[food_missing['Price'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d03ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_missing.loc[food_missing['Price'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aead74d",
   "metadata": {},
   "source": [
    "### Simple Imputation\n",
    "There are some easy methods of filling in the gaps, for example, we can replace all the missing values with the mean or median values. Let's start by calculating the mean and median prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c03856",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_price = food_missing['Price'].mean()\n",
    "median_price = food_missing['Price'].median()\n",
    "\n",
    "print('Mean price: ' + str(mean_price))\n",
    "print('Median price: ' + str(median_price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c59d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_missing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23de056",
   "metadata": {},
   "source": [
    "Now we can fill in the missing values. We start by defining two dataframes as copies of `food_missing`, one for the mean imputed values, and another for the median imputed values, and then fill them in by using the `fillna()` method. Note that the `.copy()` method is required as pandas will chain assignments of dataframes together, meaning a change to `food_mean` below would also change `food_missing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b5616a",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_mean = food_missing.copy()\n",
    "food_median = food_missing.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5fcb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_mean['Price'] = food_mean['Price'].fillna(mean_price, inplace = False)\n",
    "food_median['Price'] = food_median['Price'].fillna(median_price, inplace = False)\n",
    "\n",
    "# We can check whether the values are still missing \n",
    "food_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21760716",
   "metadata": {},
   "source": [
    "Now from our imputed datasets, say we are interested in the average price:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757f859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Imputation average price :' + str(food_mean['Price'].mean()))\n",
    "print('Median Imputation average price: ' + str(food_median['Price'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fc81be",
   "metadata": {},
   "source": [
    "So we have two different values for what the average food price in a grocery store is...which one is correct, or the better average? We now have some **uncertainty** in our estimate as a direct cause of the missing data. Multiple imputation aims to help us give better estimates from missing values and allows us to quantify the uncertainty of that estimate.\n",
    "\n",
    "But, before you do that, try out some of these imputation methods on `diabetes_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1eb80b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ffd968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea4f590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c01a1ac",
   "metadata": {},
   "source": [
    "### Multiple Imputation\n",
    "This is where we actually repeat the imputation multiple times with multiple different values. We can then calculate the statistic we are interested in - the average price - across these different inputed datasets to understand how much the statistic varies.\n",
    "\n",
    "One strategy we could try is randomly sampling prices within the range of observed prices of other groceries. The  `numpy` package has a function `.uniform(min, max, n)` which randomly generates `n` numbers between `min` and `max`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42fe84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "min_price = food_missing['Price'].min()\n",
    "max_price = food_missing['Price'].max()\n",
    "\n",
    "np.random.uniform(min_price, max_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcea552",
   "metadata": {},
   "source": [
    "We can record how many missing values we need to impute, and generate that number of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd642a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_missing_prices = sum(food_missing['Price'].isna())\n",
    "print(str(num_missing_prices) + ' missing values to impute')\n",
    "\n",
    "imputed_values = np.random.uniform(min_price, max_price, num_missing_prices)\n",
    "imputed_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4008b63a",
   "metadata": {},
   "source": [
    "If you run the previous two cells multiple times, you will see that they generate new numbers every time.\n",
    "\n",
    "Say we want to run the imputation procedure 100 times. What we will do is, looping over the values 0-99 (via the `range()` function) we will complete an imputation round in each iteration of the loop, and store the mean value from that round in a list which we can analyse afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681be9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_price = []\n",
    "\n",
    "for i in range(100):\n",
    "    # Create a new copy of the dataframe to work with\n",
    "    imputed_data = food_missing.copy()\n",
    "    \n",
    "    # Create a list of imputed values that we will insert into imputed_data\n",
    "    imputed_values = np.random.uniform(min_price, max_price, num_missing_prices)\n",
    "    \n",
    "    # Insert the missing data into the dataframe\n",
    "    imputed_data.loc[imputed_data['Price'].isna(), 'Price'] = imputed_values\n",
    "    \n",
    "    # Calculate the new average price\n",
    "    imputed_mean = imputed_data['Price'].mean()\n",
    "    \n",
    "    # Add the imputed mean to the average_price list\n",
    "    average_price = average_price + [imputed_mean]\n",
    "    \n",
    "average_price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a9987c",
   "metadata": {},
   "source": [
    "We can use some of the plotting methods earlier to visualise this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f41707e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(average_price, vert=False, labels = [''])\n",
    "ax.set_xlabel('Average grocery price');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3703e44",
   "metadata": {},
   "source": [
    "We now have a *distribution* for the average price of groceries under the uncertainty caused by the missing values - indeed 50% of the time the average fell between 2.2 and 2.4, and we could say with reasonable certainty that the true mean falls between £1.90 and £2.60.\n",
    "\n",
    "But we could probably narrow down this range of values by using other information. If you have completed the section on Plotting, you'll know that there does seem to be some relationship between `Health_Rating` and `Price` - information we could be using! This is where multiple inputation get's very interesting.\n",
    "\n",
    "Try using some of the methods you have seen on the `diabetes_df` dataframe to quantify how variable the average `SkinThickness` is due to the missing data.\n",
    "\n",
    "For those that want more of a challenge, try and impute values for the `food_missing` dataframe using information about the `Health_Rating`. Some tips:\n",
    "* For each rating, store the max and min values in a dictionary.\n",
    "    * What might you do to handle the lack of data with a `Health_Rating` of F?\n",
    "* In the imputation process, refer to that dicionary to retrieve the `min` and `max` values for the random selection.\n",
    "* Because rows with missing values have different `Health_Rating` values, you might need to iterate through each `Health_Rating`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb1dd84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30451010",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf78905",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "638bb38e",
   "metadata": {},
   "source": [
    "## Building some simple models\n",
    "\n",
    "Here we will not cover in great depth how the algorithms we are using work, only some brief details will be provided. For more information, you can head to __[this discussion of Regression](https://www.codecademy.com/article/introduction-regression-analysis)__ or __[this discussion of Random Forests](https://www.section.io/engineering-education/introduction-to-random-forest-in-machine-learning/)__. You can also head over to the '*Statistical Modelling Demo*' directory to see some more details on statistical modelling. Our objective will be to build some 'models' that can predict the outcome in certain scenarios. That is, will will not look in much detail at inference and understanding how these predictions are made."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2f0a31",
   "metadata": {},
   "source": [
    "### Example 1: `food_guide_price_df`\n",
    "Our first objective here will be to predict `Price` given a `Health_Rating`.\n",
    "#### Set Up\n",
    "We will construct a 'training' set which will be used to fit the model and 'test' set to evaluate the model. This split wil be generated by randomly selecting 25% of the dataset to include in the test set. The `sklearn` package offers useful classes and methods to split the data, train the different models we will be using, and evaluate them. Note that we set a 'random seed' to ensure that we get the same split consistently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ab2826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(9001)\n",
    "\n",
    "split = train_test_split(food_guide_price_df)\n",
    "split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9bb5f1",
   "metadata": {},
   "source": [
    "Here we can see that the output of the `train_test_split` function is a list of the form `[train, test]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b060cd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = split[0]\n",
    "test = split[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978ac19b",
   "metadata": {},
   "source": [
    "Now we pick out the columns we are using to make predictions, and the targets for both the train and test sets. We refer to the columns we use to make predictions as `X` and the targets as `y`, that is, we are using `X` to predict `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9039a008",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['Health_Rating']\n",
    "y_train = train['Price']\n",
    "\n",
    "X_test = test['Health_Rating']\n",
    "y_test = test['Price']\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456b3daa",
   "metadata": {},
   "source": [
    "To be able to construct a model which uses this categorical data, we need to *one hot encode* our data. That is, for each `health_rating`, we will have a column of 0/1 binary indicators. `sklearn` can once again help us out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f76470",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "X_train_encoded = encoder.fit_transform(np.array(X_train).reshape(-1,1))\n",
    "X_test_encoded = encoder.transform(np.array(X_test).reshape(-1,1))\n",
    "\n",
    "X_train_encoded.toarray()\n",
    "# the 12x5 matrix outputted is precisely what we wanted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16380215",
   "metadata": {},
   "source": [
    "We can see which feature is which with the `get_feature_names_out` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71be7ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdec6ee",
   "metadata": {},
   "source": [
    "That is, the columns of our matrix above are in the order A, B, X, E, F."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e287c14",
   "metadata": {},
   "source": [
    "#### Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24191cd5",
   "metadata": {},
   "source": [
    "We initiate the `LinearRegression()` class, and then fit the model based on the training data with the `.fit(X,y)` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ea5f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = LinearRegression()\n",
    "regression.fit(X_train_encoded, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a5cee0",
   "metadata": {},
   "source": [
    "Congratulations, technically you have just trained your first machine learning model! Now we can predict our test set values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41544182",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_predicted_values = regression.predict(X_test_encoded)\n",
    "regression_predicted_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477f26a0",
   "metadata": {},
   "source": [
    "Let's set up a results dataframe where we can start to see how well we are doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f42badc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_df = split[1].copy()\n",
    "test_results_df['Regression'] = regression_predicted_values\n",
    "test_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac7e518",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d22111e",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestRegressor()\n",
    "forest.fit(X_train_encoded, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b685cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_predicted_values = forest.predict(X_test_encoded)\n",
    "forest_predicted_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccfe3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_df['Forest'] = forest_predicted_values\n",
    "test_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65964ad",
   "metadata": {},
   "source": [
    "Well the linear regression model has the better predictions for two of the items, and the random forest the better predictions for the other two items, however, the predictions aren't very good. This is because we are using a very small dataset for which the training set is not representitive of the test set. Let's look at an example where we are using some more predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3713dd",
   "metadata": {},
   "source": [
    "### Example 2: `sample_df`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d9ad18",
   "metadata": {},
   "source": [
    "#### Set Up\n",
    "We split the data as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807b3782",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(9001)\n",
    "\n",
    "split_iris = train_test_split(sample_df)\n",
    "train_iris = split_iris[0]\n",
    "test_iris = split_iris[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c3d620",
   "metadata": {},
   "source": [
    "Now we will use a few more predictors - this time we will predict `petal_width` from `petal_length`, `sepal_width`, and `sepal_length`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d16f5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_iris = train_iris[['petal_length', 'sepal_width', 'sepal_length']]\n",
    "y_train_iris = train_iris['petal_width']\n",
    "\n",
    "X_test_iris = test_iris[['petal_length', 'sepal_width', 'sepal_length']]\n",
    "y_test_iris = test_iris['petal_width']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b513e38c",
   "metadata": {},
   "source": [
    "#### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b885cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_iris = LinearRegression()\n",
    "regression_iris.fit(X_train_iris, y_train_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797d6097",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bbf7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_predicted_values_iris = regression_iris.predict(X_test_iris)\n",
    "regression_predicted_values_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910fdfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_df_iris = split_iris[1].copy()\n",
    "test_results_df_iris['Regression'] = regression_predicted_values_iris\n",
    "test_results_df_iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba00861c",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da59030f",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_iris = RandomForestRegressor()\n",
    "forest_iris.fit(X_train_iris, y_train_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c396538",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_predicted_values_iris = forest_iris.predict(X_test_iris)\n",
    "forest_predicted_values_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93ebe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_df_iris['Forest'] = forest_predicted_values_iris\n",
    "test_results_df_iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f927b9",
   "metadata": {},
   "source": [
    "#### Which method performed best? \n",
    "\n",
    "A typical measure of accuracy for these types of regression tasks would be the mean squared error. That is, we calculate the difference between the true and predicted values, square them all, and take the average. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb3d55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_errors = test_results_df_iris['Regression'] - test_results_df_iris['petal_width']\n",
    "squared_reg_errors = regression_errors**2\n",
    "regression_mse = np.mean(squared_reg_errors)\n",
    "\n",
    "forest_errors = test_results_df_iris['Forest'] - test_results_df_iris['petal_width']\n",
    "squared_forest_errors = forest_errors**2\n",
    "forest_mse = np.mean(squared_forest_errors)\n",
    "\n",
    "print('Linear Regression mean squared error: ' + str(regression_mse))\n",
    "print('Random Forest mean squared error: ' + str(forest_mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8be154",
   "metadata": {},
   "source": [
    "In this case, we see that the linear regression model has a lower mean squared error, and therefore would be considered the better model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f121733",
   "metadata": {},
   "source": [
    "### Exercise: `diabetes_df`\n",
    "You have seen some examples of how we use linear regression models and random forests to predict values, and assess which method is best. Have a play with `diabetes_df`: set yourself a prediction task, try out these two models and see how well they perform. Which one was better? Explore the predictions, maybe do some plots, and try to understand the results. If you have time, maybe check out some other __[supervised learning methods](https://scikit-learn.org/stable/supervised_learning.html)__, in particular, LASSO (1.1.3), Elastic Net (1.1.5), Support Vector Machines for Regression (1.4.2) and Gradient Boosting (1.11.4) might work well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa3f647",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df = pd.read_csv('diabetes.csv')\n",
    "diabetes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7354438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8fec4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a70420d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3e1f75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da21ed34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
